{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc3548ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import importlib\n",
    "project_root = os.path.abspath(\"../\")\n",
    "sys.path.append(project_root)\n",
    "from src.data import process_data\n",
    "importlib.reload(process_data)\n",
    "from src.data.load_data import load_data\n",
    "from src.data.process_data import preproces ,clean_and_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f89b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preproces(load_data(tmdb_5000_movies='../data/raw/tmdb_5000_movies.csv', tmdb_5000_credits='../data/raw/tmdb_5000_credits.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30a92808",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_data[['overview_title','cast', 'crew']]\n",
    "y = preprocessed_data['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "279b294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Action': 0, 'Adventure': 1, 'Fantasy': 2, 'Science Fiction': 3, 'Crime': 4, 'Drama': 5, 'Thriller': 6, 'Animation': 7, 'Family': 8, 'Western': 9, 'Comedy': 10, 'Romance': 11, 'Horror': 12, 'Mystery': 13, 'History': 14, 'War': 15, 'Music': 16, 'Documentary': 17, 'Foreign': 18, 'TV Movie': 19}\n"
     ]
    }
   ],
   "source": [
    "genres_list =[genre for genres in y for genre in genres]\n",
    "element_to_index = {}\n",
    "idx = 0\n",
    "for e in genres_list:\n",
    "    if e in element_to_index:\n",
    "        continue\n",
    "    element_to_index[e] = idx\n",
    "    idx += 1\n",
    "\n",
    "print(element_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2521917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization. Avatar\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train['overview_title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8187660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer_cast = TfidfVectorizer(max_features=2500, stop_words='english')\n",
    "tfidf_vectorizer_crew = TfidfVectorizer(max_features=2500, stop_words='english')\n",
    "cast_tf_idf = tfidf_vectorizer_cast.fit_transform(X_train['cast'].apply(lambda x : ' '.join(x)))\n",
    "crew_tf_idf = tfidf_vectorizer_crew.fit_transform(X_train['crew'].apply(lambda x : ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13dc510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_tf_idf_test = tfidf_vectorizer_cast.transform(X_test['cast'].apply(lambda x : ' '.join(x)))\n",
    "crew_tf_idf_test = tfidf_vectorizer_crew.transform(X_test['crew'].apply(lambda x : ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1de1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def doc2vec(tokens,word2vec):\n",
    "    vectors = [word2vec.wv[token] for token in tokens if token in word2vec.wv]\n",
    "    vector = np.mean(vectors, axis = 0)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "980cb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'src.data.process_data' from 'e:\\\\nlp_projects\\\\Movie Genre Classification with Multi-label Output\\\\src\\\\data\\\\process_data.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X_train['overview_title'][0]))\n",
    "importlib.reload(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18e44eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4687    [fidgety, wisecracking, video, store, clerk, d...\n",
      "2951    [greenwich, village, early, gifted, volatile, ...\n",
      "4071    [agent, back, second, installment, james, bond...\n",
      "4579    [king, arthur, accompanied, squire, recruits, ...\n",
      "2197    [ally, darling, anna, faris, realizing, shes, ...\n",
      "                              ...                        \n",
      "4426    [fine, step, uplifting, family, drama, centeri...\n",
      "466     [hoping, alter, events, past, th, century, inv...\n",
      "3092    [seemingly, perfect, family, moves, suburban, ...\n",
      "3772    [drying, west, coast, alcoholic, hit, man, bef...\n",
      "860     [burlesque, lounge, best, days, behind, tess, ...\n",
      "Name: overview_title, Length: 3842, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec \n",
    "X_train['overview_title'] = X_train['overview_title'].apply(clean_and_tokenize)\n",
    "X_test['overview_title'] = X_test['overview_title'].apply(clean_and_tokenize)\n",
    "print(X_train['overview_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4daf2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=X_train['overview_title'],vector_size=300,window=5,min_count=2)\n",
    "train_overview_title_vec = [doc2vec(sentence,word2vec) for sentence in X_train['overview_title']]\n",
    "test_overview_title_vec = [doc2vec(sentence,word2vec) for sentence in X_test['overview_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5444686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "train_overview_title_vec = normalize(train_overview_title_vec)\n",
    "test_overview_title_vec = normalize(test_overview_title_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d82a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix,hstack\n",
    "\n",
    "train_overview_title_vec = csr_matrix(train_overview_title_vec)\n",
    "test_overview_title_vec = csr_matrix(test_overview_title_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9dd6810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3842, 300)\n",
      "(3842, 2500)\n",
      "(3842, 2500)\n"
     ]
    }
   ],
   "source": [
    "print(train_overview_title_vec.shape)\n",
    "print(cast_tf_idf.shape)\n",
    "print(crew_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ccbf9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = hstack([train_overview_title_vec, cast_tf_idf, crew_tf_idf])\n",
    "X_test_sparse = hstack([test_overview_title_vec, cast_tf_idf_test, crew_tf_idf_test])\n",
    "\n",
    "# Then convert to dense\n",
    "X_train = X_train_sparse.toarray()\n",
    "X_test = X_test_sparse.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef77d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3842, 5300)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6669837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset,DataLoader \n",
    "# import torch\n",
    "def encode_genres(genres,element_to_index):\n",
    "    encoded = [0]* len(element_to_index)\n",
    "    for genre in genres:\n",
    "        encoded[element_to_index[genre]] = 1 \n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# class movies_dataset(Dataset):\n",
    "#     def __init__(self,X,y,element_to_index):\n",
    "#         self.X = X \n",
    "#         self.y = y \n",
    "#         self.encoded = [encode_genres(genres,element_to_index) for genres in y]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.X)\n",
    "    \n",
    "#     def __getitem__(self,idx):\n",
    "#         return torch.tensor(self.X[idx],dtype=torch.float32),torch.tensor(self.encoded[idx],dtype=torch.float32)\n",
    "\n",
    "# train_dataset = movies_dataset(X_train,y_train,element_to_index)\n",
    "# train_loader = DataLoader(train_dataset,batch_size= 32,shuffle=True)\n",
    "# test_dataset = movies_dataset(X_test,y_test,element_to_index)\n",
    "# test_loader = DataLoader(test_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6209143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import FFN \n",
    "# importlib.reload(FFN)\n",
    "# from models.FFN import FNN_model\n",
    "# fnn_model = FNN_model(input_dim=4300,hidden_dim=300,output_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be9eb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.train_and_evaluate import train_model\n",
    "# criterian = torch.nn.BCELoss()\n",
    "# optim = torch.optim.SGD(fnn_model.parameters())\n",
    "# train_model(fnn_model,criterian,optim=optim,epochs=250,loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7ba3eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import train_and_evaluate \n",
    "# importlib.reload(train_and_evaluate)\n",
    "# from models.train_and_evaluate import evaluate \n",
    "# print(evaluate(fnn_model,test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "encoded_train = [encode_genres(genres,element_to_index) for genres in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e44d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(LogisticRegression())\n",
    "model.fit(X_train,encoded_train)\n",
    "preds = model.predict_proba(X_test)\n",
    "preds = (preds >= 0.2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb1de969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "encoded_test = [encode_genres(genres,element_to_index) for genres in y_test]\n",
    "f1_micro = f1_score(encoded_test, preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8d30ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49596309111880044\n"
     ]
    }
   ],
   "source": [
    "print(f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e84c139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# model = OneVsRestClassifier(GradientBoostingClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15bb4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train,encoded_train)\n",
    "# preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99aa88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_test = [encode_genres(genres,element_to_index) for genres in y_test]\n",
    "# f1_micro = f1_score(encoded_test, preds, average='micro')\n",
    "# print(f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2cc15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
